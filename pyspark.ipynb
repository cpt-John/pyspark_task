{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> for pyspark installed seperately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/spark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName('Test').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> read csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"./employees.csv\",)\n",
    "df.printSchema()\n",
    "# print all rows\n",
    "df.show(df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|First Name|Last Name|\n",
      "+----------+---------+\n",
      "|   Theresa|      Lee|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select max salary employee\n",
    "max_val = df.select(df['Salary'].cast(\"int\")).rdd.max()[0]\n",
    "df.filter(f\"Salary == '{max_val}'\").select(\"First Name\", \"Last Name\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> save by partitioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\"First Name\", \"Last Name\", \"Date of Joining\", \"Gender\").write.option(\"header\", True) \\\n",
    "    .partitionBy(\"Gender\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"partition_gender\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      avg|\n",
      "+---------+\n",
      "|119738.09|\n",
      "+---------+\n",
      "\n",
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  100|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "|  min|\n",
      "+-----+\n",
      "|42005|\n",
      "+-----+\n",
      "\n",
      "+------+\n",
      "|   max|\n",
      "+------+\n",
      "|197537|\n",
      "+------+\n",
      "\n",
      "+-----------------+\n",
      "|           stddev|\n",
      "+-----------------+\n",
      "|46185.27819425479|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count, min, max, stddev\n",
    "funcs = {\n",
    "    \"avg\": avg,\n",
    "    \"count\": count,\n",
    "    \"min\": min,\n",
    "    \"max\": max,\n",
    "    \"stddev\": stddev,\n",
    "}\n",
    "for key, val in funcs.items():\n",
    "    df.select(val(df['Salary'].cast(\"int\")).alias(key)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+--------------------+-------------+---------------+------+-----------+------------+--------------+--------------+-----+-----------------+\n",
      "|Emp ID|First Name|Last Name|Gender|              E Mail|Date of Birth|Date of Joining|Salary|Last % Hike|  Phone No. |        County|          City|  Zip|Days from Joining|\n",
      "+------+----------+---------+------+--------------------+-------------+---------------+------+-----------+------------+--------------+--------------+-----+-----------------+\n",
      "|677509|      Lois|   Walker|     F|lois.walker@hotma...|    3/29/1981|     11/24/2003|168251|        21%|303-572-8492|        Denver|        Denver|80224|             7032|\n",
      "|940761|    Brenda| Robinson|     F|brenda.robinson@g...|    7/31/1970|      7/27/2008| 51063|        27%|225-945-4954|       De Soto|     Stonewall|71078|             5203|\n",
      "|428945|       Joe| Robinson|     M|joe.robinson@gmai...|    6/16/1963|       8/3/2016| 50155|        16%|219-904-2161|       Clinton|  Michigantown|46057|             2305|\n",
      "|408351|     Diane|    Evans|     F|diane.evans@yahoo...|    12/4/1977|      4/16/1999|180294|         1%|215-793-6791|      Crawford|      Hydetown|16328|             8501|\n",
      "|193819|  Benjamin|  Russell|     M|benjamin.russell@...|    4/17/1977|      7/25/2013|117642|        13%|262-404-2252|       Waupaca|       Fremont|54940|             3378|\n",
      "|499687|   Patrick|   Bailey|     M|patrick.bailey@ao...|    9/27/1982|      7/22/2005| 72305|         5%|319-812-6957|       Madison|     Macksburg|50155|             6303|\n",
      "|539712|     Nancy|    Baker|     F|  nancy.baker@bp.com|    6/13/1995|      9/14/2016| 98189|         0%|229-336-5117|        Fulton|       Atlanta|30334|             2294|\n",
      "|380086|     Carol|   Murphy|     F|carol.murphy@gmai...|    6/30/1958|      1/28/1983| 60918|        20%|216-336-0009|       Clinton|   Blanchester|45107|            14333|\n",
      "|477616|   Frances|    Young|     F|frances.young@gma...|     6/9/1959|      4/27/1994|121587|        28%|210-819-9765|         Starr|       Delmita|78536|            10316|\n",
      "|162402|     Diana| Peterson|     F|diana.peterson@ho...|   11/13/1987|      2/17/2014| 43010|         4%|479-783-5656|       Carroll|Eureka Springs|72632|             3021|\n",
      "|231469|     Ralph|   Flores|     M|ralph.flores@yaho...|     2/5/1975|      4/14/2009|118457|         8%|316-280-2864|        Nemaha|       Sabetha|66534|             4850|\n",
      "|153989|      Jack|Alexander|     M|jack.alexander@gm...|    5/19/1995|       1/5/2017| 82965|        23%|702-603-3769|         Clark|     Las Vegas|89170|             1937|\n",
      "|386158|   Melissa|     King|     F|melissa.king@comc...|    2/24/1972|     11/24/2015|166892|         1%|216-605-3731|    Washington| New Matamoras|45767|             2649|\n",
      "|301576|     Wayne|   Watson|     M|wayne.watson@gmai...|    6/26/1996|      7/19/2017| 92758|        14%|701-231-9370|      Cavalier|         Maida|58255|             1923|\n",
      "|441771|    Cheryl|    Scott|     F|cheryl.scott@gmai...|    2/23/1958|     11/26/1990| 92220|        12%|215-288-9345|      Somerset|      Quecreek|15555|            11778|\n",
      "|528509|     Paula|     Diaz|     F|paula.diaz@gmail.com|    8/22/1966|      8/22/1994|152654|         8%|252-531-7641|        Duplin|    Beulaville|28518|            10321|\n",
      "|912990|    Joshua|  Stewart|     M|joshua.stewart@ya...|    5/18/1970|       9/2/2002|184896|         1%|217-279-9342|       Madison|   New Douglas|62074|             7419|\n",
      "|214352|   Theresa|      Lee|     F|theresa.lee@gmail...|    12/5/1992|      1/19/2015|197537|         1%|319-553-8919|      Mitchell|   Toeterville|50481|             2654|\n",
      "|890290|     Julia|    Scott|     F|julia.scott@apple...|    7/15/1959|      2/23/2005|141518|         3%|423-939-1010|       Hickman| Primm Springs|38476|             6302|\n",
      "|622406|    Thomas|    Lewis|     M|thomas.lewis@gmai...|    10/4/1967|       6/7/1998| 73862|         3%|314-679-3697|Cape Girardeau|     Dutchtown|63745|             8875|\n",
      "+------+----------+---------+------+--------------------+-------------+---------------+------+-----------+------------+--------------+--------------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import lit, to_date, current_date, col, datediff\n",
    "\n",
    "# find number of days from joining\n",
    "df.withColumn('Days from Joining',\n",
    "              datediff(current_date(), to_date(\n",
    "                  df['Date of Joining'], 'm/d/yyyy'))\n",
    "              ).show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
